{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "682f35f1",
   "metadata": {},
   "source": [
    "# CSC 8614 - Language Models\n",
    "## CI3 - Parameter-Efficient Fine-Tuning with LoRA\n",
    "\n",
    "This TP builds upon the GPT architecture we have previously explored. \n",
    "\n",
    "We will implement Low-Rank Adaptation (LoRA) from scratch and inject it into our pre-existing GPTModel.\n",
    "\n",
    "Objectives:\n",
    "- Implement the mathematical formulation of LoRA.\n",
    "- Create a wrapper to convert standard Linear layers into LoRA-compatible layers.\n",
    "- Inject these layers into a pre-trained GPT model.\n",
    "- Verify that only a fraction of parameters are trainable.\n",
    "- Fine-tune the model with LoRA\n",
    "\n",
    "Some of this code comes from the book _Build a Large Language Model (From Scratch)_, by Sebastian Raschka, and its [official github repository](https://github.com/rasbt/LLMs-from-scratch).\n",
    "\n",
    "This TP will be done in this notebook, and requires some additional files (available from the course website). \n",
    "You will have to fill the missing portions of code, and perform some additional experiments by testing different parameters.\n",
    "\n",
    "Working on this TP:\n",
    "- The easiest way is probably to work directly on the notebook, using jupyter notebook or visual studio code. An alternative is also to use Google colab.\n",
    "- You should be able to run everything on your machine, but you can connect to the GPUs if needed.\n",
    "- **NOTE**: run the cells in the correct order, otherwise you might get errors due to inconsintencies.\n",
    "\n",
    "Some files are required, and are available on the course website and/or github repo:\n",
    "- `requirements.txt`\n",
    "- `gpt_utils.py`\n",
    "\n",
    "\n",
    "## About the report\n",
    "You will have to return this notebook (completed), as well as a mini-report (`TP3/rapport.md`).\n",
    "\n",
    "The notebook and report shall be submitted via a GitHub repository, similarly to what you did for the previous sessions (remember to use a different folder: `TP3`).\n",
    "For the notebook, it is sufficient to complete the code and submit the final version.\n",
    "\n",
    "For the mini-report, you have to answer the questions asked in this notebook, and discuss some of your findings as requested.\n",
    "Same as in the previous sessions:\n",
    "- You must include: short answers, observed results (copies of outputs), requested screenshots, and a brief interpretation.\n",
    "- Do not paste entire pages: be concise and select the relevant elements.\n",
    "\n",
    "Reproducibility: \n",
    "- fix a random seed and write it in the report\n",
    "- indicate in the report the specific python version OS, and the library versions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a8ead2",
   "metadata": {},
   "source": [
    "## Prerequisite\n",
    "\n",
    "Install the requirements.\n",
    "\n",
    "**Note**: if you use the same virtual environment as last time, you will not have to reinstall everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "347af8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.9.1 (from -r requirements.txt (line 1))\n",
      "  Obtaining dependency information for torch==2.9.1 from https://files.pythonhosted.org/packages/47/cc/7a2949e38dfe3244c4df21f0e1c27bce8aedd6c604a587dd44fc21017cb4/torch-2.9.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached torch-2.9.1-cp311-cp311-win_amd64.whl.metadata (30 kB)\n",
      "Collecting tiktoken==0.12.0 (from -r requirements.txt (line 2))\n",
      "  Obtaining dependency information for tiktoken==0.12.0 from https://files.pythonhosted.org/packages/9d/15/963819345f1b1fb0809070a79e9dd96938d4ca41297367d471733e79c76c/tiktoken-0.12.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tiktoken-0.12.0-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting tqdm==4.67.1 (from -r requirements.txt (line 3))\n",
      "  Obtaining dependency information for tqdm==4.67.1 from https://files.pythonhosted.org/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/57.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/57.7 kB ? eta -:--:--\n",
      "     ------- -------------------------------- 10.2/57.7 kB ? eta -:--:--\n",
      "     -------------------- ----------------- 30.7/57.7 kB 330.3 kB/s eta 0:00:01\n",
      "     -------------------------------------- 57.7/57.7 kB 435.2 kB/s eta 0:00:00\n",
      "Collecting pandas==2.3.3 (from -r requirements.txt (line 4))\n",
      "  Obtaining dependency information for pandas==2.3.3 from https://files.pythonhosted.org/packages/8e/59/712db1d7040520de7a4965df15b774348980e6df45c129b8c64d0dbe74ef/pandas-2.3.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached pandas-2.3.3-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting matplotlib==3.10.8 (from -r requirements.txt (line 5))\n",
      "  Obtaining dependency information for matplotlib==3.10.8 from https://files.pythonhosted.org/packages/6f/d3/a4bbc01c237ab710a1f22b4da72f4ff6d77eb4c7735ea9811a94ae239067/matplotlib-3.10.8-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached matplotlib-3.10.8-cp311-cp311-win_amd64.whl.metadata (52 kB)\n",
      "Collecting tensorflow==2.20.0 (from -r requirements.txt (line 6))\n",
      "  Obtaining dependency information for tensorflow==2.20.0 from https://files.pythonhosted.org/packages/e3/f8/9246d3c7e185a29d7359d8b12b3d70bf2c3150ecf1427ec1382290e71a56/tensorflow-2.20.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tensorflow-2.20.0-cp311-cp311-win_amd64.whl.metadata (4.6 kB)\n",
      "Collecting jupyterlab==4.5.1 (from -r requirements.txt (line 7))\n",
      "  Obtaining dependency information for jupyterlab==4.5.1 from https://files.pythonhosted.org/packages/af/c3/acced767eecc11a70c65c45295db5396c4f0c1937874937d5a76d7b177b6/jupyterlab-4.5.1-py3-none-any.whl.metadata\n",
      "  Downloading jupyterlab-4.5.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting filelock (from torch==2.9.1->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/b5/36/7fb70f04bf00bc646cd5bb45aa9eddb15e19437a28b8fb2b4a5249fac770/filelock-3.20.3-py3-none-any.whl.metadata\n",
      "  Downloading filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from torch==2.9.1->-r requirements.txt (line 1)) (4.15.0)\n",
      "Collecting sympy>=1.13.3 (from torch==2.9.1->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for sympy>=1.13.3 from https://files.pythonhosted.org/packages/a2/09/77d55d46fd61b4a135c444fc97158ef34a095e5681d0a6c10b75bf356191/sympy-1.14.0-py3-none-any.whl.metadata\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch==2.9.1->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for networkx>=2.5.1 from https://files.pythonhosted.org/packages/9e/c9/b2622292ea83fbb4ec318f5b9ab867d0a28ab43c5717bb85b0a5f6b3b0a4/networkx-3.6.1-py3-none-any.whl.metadata\n",
      "  Using cached networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jinja2 (from torch==2.9.1->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for jinja2 from https://files.pythonhosted.org/packages/62/a1/3d680cbfd5f4b8f15abc1d571870c5fc3e594bb582bc3b64ea099db13e56/jinja2-3.1.6-py3-none-any.whl.metadata\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=0.8.5 (from torch==2.9.1->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for fsspec>=0.8.5 from https://files.pythonhosted.org/packages/01/c9/97cc5aae1648dcb851958a3ddf73ccd7dbe5650d95203ecb4d7720b4cdbf/fsspec-2026.1.0-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2026.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken==0.12.0->-r requirements.txt (line 2))\n",
      "  Obtaining dependency information for regex>=2022.1.18 from https://files.pythonhosted.org/packages/0f/19/772cf8b5fc803f5c89ba85d8b1870a1ca580dc482aa030383a9289c82e44/regex-2026.1.15-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading regex-2026.1.15-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "     ---------------------------------------  41.0/41.5 kB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- 41.5/41.5 kB 401.1 kB/s eta 0:00:00\n",
      "Collecting requests>=2.26.0 (from tiktoken==0.12.0->-r requirements.txt (line 2))\n",
      "  Obtaining dependency information for requests>=2.26.0 from https://files.pythonhosted.org/packages/1e/db/4254e3eabe8020b458f1a747140d32277ec7a271daf1d235b70dc0b4e6e3/requests-2.32.5-py3-none-any.whl.metadata\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from tqdm==4.67.1->-r requirements.txt (line 3)) (0.4.6)\n",
      "Collecting numpy>=1.23.2 (from pandas==2.3.3->-r requirements.txt (line 4))\n",
      "  Obtaining dependency information for numpy>=1.23.2 from https://files.pythonhosted.org/packages/8c/de/f5e79650d23d9e12f38a7bc6b03ea0835b9575494f8ec94c11c6e773b1b1/numpy-2.4.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading numpy-2.4.1-cp311-cp311-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from pandas==2.3.3->-r requirements.txt (line 4)) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas==2.3.3->-r requirements.txt (line 4))\n",
      "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/81/c4/34e93fe5f5429d7570ec1fa436f1986fb1f00c3e0f43a589fe2bbcd22c3f/pytz-2025.2-py2.py3-none-any.whl.metadata\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas==2.3.3->-r requirements.txt (line 4))\n",
      "  Obtaining dependency information for tzdata>=2022.7 from https://files.pythonhosted.org/packages/c7/b0/003792df09decd6849a5e39c28b513c06e84436a54440380862b5aeff25d/tzdata-2025.3-py2.py3-none-any.whl.metadata\n",
      "  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib==3.10.8->-r requirements.txt (line 5))\n",
      "  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/98/4b/9bd370b004b5c9d8045c6c33cf65bae018b27aca550a3f657cdc99acdbd8/contourpy-1.3.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached contourpy-1.3.3-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib==3.10.8->-r requirements.txt (line 5))\n",
      "  Obtaining dependency information for cycler>=0.10 from https://files.pythonhosted.org/packages/e7/05/c19819d5e3d95294a6f5947fb9b9629efb316b96de511b418c53d245aae6/cycler-0.12.1-py3-none-any.whl.metadata\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib==3.10.8->-r requirements.txt (line 5))\n",
      "  Obtaining dependency information for fonttools>=4.22.0 from https://files.pythonhosted.org/packages/07/ad/37dd1ae5fa6e01612a1fbb954f0927681f282925a86e86198ccd7b15d515/fonttools-4.61.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached fonttools-4.61.1-cp311-cp311-win_amd64.whl.metadata (116 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib==3.10.8->-r requirements.txt (line 5))\n",
      "  Obtaining dependency information for kiwisolver>=1.3.1 from https://files.pythonhosted.org/packages/3b/c6/f8df8509fd1eee6c622febe54384a96cfaf4d43bf2ccec7a0cc17e4715c9/kiwisolver-1.4.9-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached kiwisolver-1.4.9-cp311-cp311-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from matplotlib==3.10.8->-r requirements.txt (line 5)) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib==3.10.8->-r requirements.txt (line 5))\n",
      "  Obtaining dependency information for pillow>=8 from https://files.pythonhosted.org/packages/6c/af/b1d7e301c4cd26cd45d4af884d9ee9b6fab893b0ad2450d4746d74a6968c/pillow-12.1.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached pillow-12.1.0-cp311-cp311-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib==3.10.8->-r requirements.txt (line 5))\n",
      "  Obtaining dependency information for pyparsing>=3 from https://files.pythonhosted.org/packages/8b/40/2614036cdd416452f5bf98ec037f38a1afb17f327cb8e6b652d4729e0af8/pyparsing-3.3.1-py3-none-any.whl.metadata\n",
      "  Using cached pyparsing-3.3.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow==2.20.0->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for absl-py>=1.0.0 from https://files.pythonhosted.org/packages/8f/aa/ba0014cc4659328dc818a28827be78e6d97312ab0cb98105a770924dc11e/absl_py-2.3.1-py3-none-any.whl.metadata\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow==2.20.0->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for astunparse>=1.6.0 from https://files.pythonhosted.org/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl.metadata\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow==2.20.0->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for flatbuffers>=24.3.25 from https://files.pythonhosted.org/packages/e8/2d/d2a548598be01649e2d46231d151a6c56d10b964d94043a335ae56ea2d92/flatbuffers-25.12.19-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-25.12.19-py2.py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow==2.20.0->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 from https://files.pythonhosted.org/packages/1d/33/f1c6a276de27b7d7339a34749cc33fa87f077f921969c47185d34a887ae2/gast-0.7.0-py3-none-any.whl.metadata\n",
      "  Downloading gast-0.7.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow==2.20.0->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for google_pasta>=0.1.1 from https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl.metadata\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow==2.20.0->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for libclang>=13.0.0 from https://files.pythonhosted.org/packages/0b/2d/3f480b1e1d31eb3d6de5e3ef641954e5c67430d5ac93b7fa7e07589576c7/libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow==2.20.0->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for opt_einsum>=2.3.2 from https://files.pythonhosted.org/packages/23/cd/066e86230ae37ed0be70aae89aabf03ca8d9f39c8aea0dec8029455b5540/opt_einsum-3.4.0-py3-none-any.whl.metadata\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow==2.20.0->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for protobuf>=5.28.0 from https://files.pythonhosted.org/packages/31/ad/e5693e1974a28869e7cd244302911955c1cebc0161eb32dfa2b25b6e96f0/protobuf-6.33.4-cp310-abi3-win_amd64.whl.metadata\n",
      "  Downloading protobuf-6.33.4-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from tensorflow==2.20.0->-r requirements.txt (line 6)) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from tensorflow==2.20.0->-r requirements.txt (line 6)) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==2.20.0->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for termcolor>=1.1.0 from https://files.pythonhosted.org/packages/33/d1/8bb87d21e9aeb323cc03034f5eaf2c8f69841e40e4853c2627edf8111ed3/termcolor-3.3.0-py3-none-any.whl.metadata\n",
      "  Downloading termcolor-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow==2.20.0->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for wrapt>=1.11.0 from https://files.pythonhosted.org/packages/70/5d/8f3d7eea52f22638748f74b102e38fdf88cb57d08ddeb7827c476a20b01b/wrapt-2.0.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading wrapt-2.0.1-cp311-cp311-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.20.0->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for grpcio<2.0,>=1.24.3 from https://files.pythonhosted.org/packages/60/9c/5c359c8d4c9176cfa3c61ecd4efe5affe1f38d9bae81e81ac7186b4c9cc8/grpcio-1.76.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading grpcio-1.76.0-cp311-cp311-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow==2.20.0->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for tensorboard~=2.20.0 from https://files.pythonhosted.org/packages/9c/d9/a5db55f88f258ac669a92858b70a714bbbd5acd993820b41ec4a96a4d77f/tensorboard-2.20.0-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow==2.20.0->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for keras>=3.10.0 from https://files.pythonhosted.org/packages/d8/e5/8b40bada1f33f25deca7bad0e8c7ca6752f2b09e8018e2fc4693858dd662/keras-3.13.1-py3-none-any.whl.metadata\n",
      "  Downloading keras-3.13.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow==2.20.0->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for h5py>=3.11.0 from https://files.pythonhosted.org/packages/23/95/499b4e56452ef8b6c95a271af0dde08dac4ddb70515a75f346d4f400579b/h5py-3.15.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading h5py-3.15.1-cp311-cp311-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow==2.20.0->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for ml_dtypes<1.0.0,>=0.5.1 from https://files.pythonhosted.org/packages/b4/24/70bd59276883fdd91600ca20040b41efd4902a923283c4d6edcb1de128d2/ml_dtypes-0.5.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading ml_dtypes-0.5.4-cp311-cp311-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting async-lru>=1.0.0 (from jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for async-lru>=1.0.0 from https://files.pythonhosted.org/packages/03/49/d10027df9fce941cb8184e78a02857af36360d33e1721df81c5ed2179a1a/async_lru-2.0.5-py3-none-any.whl.metadata\n",
      "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting httpx<1,>=0.25.0 (from jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for httpx<1,>=0.25.0 from https://files.pythonhosted.org/packages/2a/39/e50c7c3a983047577ee07d2a9e53faf5a69493943ec3f6a384bdc792deb2/httpx-0.28.1-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: ipykernel!=6.30.0,>=6.5.0 in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from jupyterlab==4.5.1->-r requirements.txt (line 7)) (7.1.0)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from jupyterlab==4.5.1->-r requirements.txt (line 7)) (5.9.1)\n",
      "Collecting jupyter-lsp>=2.0.0 (from jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for jupyter-lsp>=2.0.0 from https://files.pythonhosted.org/packages/1a/60/1f6cee0c46263de1173894f0fafcb3475ded276c472c14d25e0280c18d6d/jupyter_lsp-2.3.0-py3-none-any.whl.metadata\n",
      "  Downloading jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for jupyter-server<3,>=2.4.0 from https://files.pythonhosted.org/packages/92/80/a24767e6ca280f5a49525d987bf3e4d7552bf67c8be07e8ccf20271f8568/jupyter_server-2.17.0-py3-none-any.whl.metadata\n",
      "  Downloading jupyter_server-2.17.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting jupyterlab-server<3,>=2.28.0 (from jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for jupyterlab-server<3,>=2.28.0 from https://files.pythonhosted.org/packages/e0/07/a000fe835f76b7e1143242ab1122e6362ef1c03f23f83a045c38859c2ae0/jupyterlab_server-2.28.0-py3-none-any.whl.metadata\n",
      "  Downloading jupyterlab_server-2.28.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting notebook-shim>=0.2 (from jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for notebook-shim>=0.2 from https://files.pythonhosted.org/packages/f9/33/bd5b9137445ea4b680023eb0469b2bb969d61303dedb2aac6560ff3d14a1/notebook_shim-0.2.4-py3-none-any.whl.metadata\n",
      "  Downloading notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: tornado>=6.2.0 in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from jupyterlab==4.5.1->-r requirements.txt (line 7)) (6.5.4)\n",
      "Requirement already satisfied: traitlets in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from jupyterlab==4.5.1->-r requirements.txt (line 7)) (5.14.3)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow==2.20.0->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for wheel<1.0,>=0.23.0 from https://files.pythonhosted.org/packages/0b/2c/87f3254fd8ffd29e4c02732eee68a83a1d3c346ae39bc6822dcbcb697f2b/wheel-0.45.1-py3-none-any.whl.metadata\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting anyio (from httpx<1,>=0.25.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for anyio from https://files.pythonhosted.org/packages/38/0e/27be9fdef66e72d64c0cdc3cc2823101b80585f8119b5c112c2e8f5f7dab/anyio-4.12.1-py3-none-any.whl.metadata\n",
      "  Using cached anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting certifi (from httpx<1,>=0.25.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for certifi from https://files.pythonhosted.org/packages/e6/ad/3cc14f097111b4de0040c83a525973216457bbeeb63739ef1ed275c1c021/certifi-2026.1.4-py3-none-any.whl.metadata\n",
      "  Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.25.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/7e/f5/f66802a942d491edb555dd61e3a9961140fd64c90bce1eafd741609d334d/httpcore-1.0.9-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<1,>=0.25.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for idna from https://files.pythonhosted.org/packages/0e/61/66938bbb5fc52dbdf84594873d5b51fb1f7c7794e9c0f5bd885f30bc507b/idna-3.11-py3-none-any.whl.metadata\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for h11>=0.16 from https://files.pythonhosted.org/packages/04/4b/29cac41a4d98d144bf5f6d33995617b185d14b22401f75ca86f384e87ff1/h11-0.16.0-py3-none-any.whl.metadata\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (1.8.19)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (9.9.0)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (8.8.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (1.6.0)\n",
      "Requirement already satisfied: psutil>=5.7 in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (7.2.1)\n",
      "Requirement already satisfied: pyzmq>=25 in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (27.1.0)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.9.1->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for MarkupSafe>=2.0 from https://files.pythonhosted.org/packages/83/8a/4414c03d3f891739326e1783338e48fb49781cc915b2e0ee052aa490d586/markupsafe-3.0.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached markupsafe-3.0.3-cp311-cp311-win_amd64.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from jupyter-core->jupyterlab==4.5.1->-r requirements.txt (line 7)) (4.5.1)\n",
      "Collecting argon2-cffi>=21.1 (from jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for argon2-cffi>=21.1 from https://files.pythonhosted.org/packages/4f/d3/a8b22fa575b297cd6e3e3b0155c7e25db170edf1c74783d6a31a2490b8d9/argon2_cffi-25.1.0-py3-none-any.whl.metadata\n",
      "  Downloading argon2_cffi-25.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for jupyter-events>=0.11.0 from https://files.pythonhosted.org/packages/e2/48/577993f1f99c552f18a0428731a755e06171f9902fa118c379eb7c04ea22/jupyter_events-0.12.0-py3-none-any.whl.metadata\n",
      "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for jupyter-server-terminals>=0.4.4 from https://files.pythonhosted.org/packages/d1/2d/6674563f71c6320841fc300911a55143925112a72a883e2ca71fba4c618d/jupyter_server_terminals-0.5.4-py3-none-any.whl.metadata\n",
      "  Downloading jupyter_server_terminals-0.5.4-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting nbconvert>=6.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for nbconvert>=6.4.4 from https://files.pythonhosted.org/packages/cc/9a/cd673b2f773a12c992f41309ef81b99da1690426bd2f96957a7ade0d3ed7/nbconvert-7.16.6-py3-none-any.whl.metadata\n",
      "  Downloading nbconvert-7.16.6-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting nbformat>=5.3.0 (from jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for nbformat>=5.3.0 from https://files.pythonhosted.org/packages/a9/82/0340caa499416c78e5d8f5f05947ae4bc3cba53c9f038ab6e9ed964e22f1/nbformat-5.10.4-py3-none-any.whl.metadata\n",
      "  Downloading nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for overrides>=5.0 from https://files.pythonhosted.org/packages/2c/ab/fc8290c6a4c722e5514d80f62b2dc4c4df1a68a41d1364e625c35990fcf3/overrides-7.7.0-py3-none-any.whl.metadata\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting prometheus-client>=0.9 (from jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for prometheus-client>=0.9 from https://files.pythonhosted.org/packages/74/c3/24a2f845e3917201628ecaba4f18bab4d18a337834c1df2a159ee9d22a42/prometheus_client-0.24.1-py3-none-any.whl.metadata\n",
      "  Downloading prometheus_client-0.24.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting pywinpty>=2.0.1 (from jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for pywinpty>=2.0.1 from https://files.pythonhosted.org/packages/a6/a1/409c1651c9f874d598c10f51ff586c416625601df4bca315d08baec4c3e3/pywinpty-3.0.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading pywinpty-3.0.2-cp311-cp311-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting send2trash>=1.8.2 (from jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for send2trash>=1.8.2 from https://files.pythonhosted.org/packages/1c/78/504fdd027da3b84ff1aecd9f6957e65f35134534ccc6da8628eb71e76d3f/send2trash-2.1.0-py3-none-any.whl.metadata\n",
      "  Downloading send2trash-2.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for terminado>=0.8.3 from https://files.pythonhosted.org/packages/6a/9e/2064975477fdc887e47ad42157e214526dcad8f317a948dee17e1659a62f/terminado-0.18.1-py3-none-any.whl.metadata\n",
      "  Downloading terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting websocket-client>=1.7 (from jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for websocket-client>=1.7 from https://files.pythonhosted.org/packages/34/db/b10e48aa8fff7407e67470363eac595018441cf32d5e1001567a7aeba5d2/websocket_client-1.9.0-py3-none-any.whl.metadata\n",
      "  Downloading websocket_client-1.9.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting babel>=2.10 (from jupyterlab-server<3,>=2.28.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for babel>=2.10 from https://files.pythonhosted.org/packages/b7/b8/3fe70c75fe32afc4bb507f75563d39bc5642255d1d94f1f23604725780bf/babel-2.17.0-py3-none-any.whl.metadata\n",
      "  Downloading babel-2.17.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.28.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for json5>=0.9.0 from https://files.pythonhosted.org/packages/d7/9e/038522f50ceb7e74f1f991bf1b699f24b0c2bbe7c390dd36ad69f4582258/json5-0.13.0-py3-none-any.whl.metadata\n",
      "  Downloading json5-0.13.0-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting jsonschema>=4.18.0 (from jupyterlab-server<3,>=2.28.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for jsonschema>=4.18.0 from https://files.pythonhosted.org/packages/69/90/f63fb5873511e014207a475e2bb4e8b2e570d655b00ac19a9a0ca0a385ee/jsonschema-4.26.0-py3-none-any.whl.metadata\n",
      "  Downloading jsonschema-4.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow==2.20.0->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for rich from https://files.pythonhosted.org/packages/25/7a/b0178788f8dc6cafce37a212c99565fa1fe7872c70c6c9c1e1a372d9d88f/rich-14.2.0-py3-none-any.whl.metadata\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow==2.20.0->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for namex from https://files.pythonhosted.org/packages/b2/bc/465daf1de06409cdd4532082806770ee0d8d7df434da79c76564d0f69741/namex-0.1.0-py3-none-any.whl.metadata\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow==2.20.0->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for optree from https://files.pythonhosted.org/packages/d5/a3/91942b7e6e365f4e05d196dbbb52909aae11f1e2f4b4c8aee5b506f93877/optree-0.18.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading optree-0.18.0-cp311-cp311-win_amd64.whl.metadata (35 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.26.0->tiktoken==0.12.0->-r requirements.txt (line 2))\n",
      "  Obtaining dependency information for charset_normalizer<4,>=2 from https://files.pythonhosted.org/packages/65/f6/62fdd5feb60530f50f7e38b4f6a1d5203f4d16ff4f9f0952962c044e919a/charset_normalizer-3.4.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading charset_normalizer-3.4.4-cp311-cp311-win_amd64.whl.metadata (38 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.26.0->tiktoken==0.12.0->-r requirements.txt (line 2))\n",
      "  Obtaining dependency information for urllib3<3,>=1.21.1 from https://files.pythonhosted.org/packages/39/08/aaaad47bc4e9dc8c725e68f9d04865dbcb2052843ff09c97b08904852d84/urllib3-2.6.3-py3-none-any.whl.metadata\n",
      "  Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch==2.9.1->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for mpmath<1.4,>=1.1.0 from https://files.pythonhosted.org/packages/43/e3/7d92a15f894aa0c9c4b49b8ee9ac9850d6e63b03c9c32c0367a13ae62209/mpmath-1.3.0-py3-none-any.whl.metadata\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow==2.20.0->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for markdown>=2.6.8 from https://files.pythonhosted.org/packages/70/81/54e3ce63502cd085a0c556652a4e1b919c45a446bd1e5300e10c44c8c521/markdown-3.10-py3-none-any.whl.metadata\n",
      "  Downloading markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow==2.20.0->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/7a/13/e503968fefabd4c6b2650af21e110aa8466fe21432cd7c43a84577a89438/tensorboard_data_server-0.7.2-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow==2.20.0->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for werkzeug>=1.0.1 from https://files.pythonhosted.org/packages/ad/e4/8d97cca767bcc1be76d16fb76951608305561c6e056811587f36cb1316a8/werkzeug-3.1.5-py3-none-any.whl.metadata\n",
      "  Downloading werkzeug-3.1.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting argon2-cffi-bindings (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for argon2-cffi-bindings from https://files.pythonhosted.org/packages/e2/c6/a759ece8f1829d1f162261226fbfd2c6832b3ff7657384045286d2afa384/argon2_cffi_bindings-25.1.0-cp39-abi3-win_amd64.whl.metadata\n",
      "  Downloading argon2_cffi_bindings-25.1.0-cp39-abi3-win_amd64.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: decorator>=4.3.2 in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.19.2)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.6.3)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for attrs>=22.2.0 from https://files.pythonhosted.org/packages/3a/2a/7cc015f5b9f5db42b7d48157e23356022889fc354a2813c15934b7cb5c0e/attrs-25.4.0-py3-none-any.whl.metadata\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for jsonschema-specifications>=2023.03.6 from https://files.pythonhosted.org/packages/41/45/1a4ed80516f02155c51f51e8cedb3c1902296743db0bbc66608a0db2814f/jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata\n",
      "  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for referencing>=0.28.4 from https://files.pythonhosted.org/packages/2c/58/ca301544e1fa93ed4f80d724bf5b194f6e4b945841c5bfd555878eea9fcb/referencing-0.37.0-py3-none-any.whl.metadata\n",
      "  Downloading referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.25.0 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for rpds-py>=0.25.0 from https://files.pythonhosted.org/packages/fa/5b/e7b7aa136f28462b344e652ee010d4de26ee9fd16f1bfd5811f5153ccf89/rpds_py-0.30.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading rpds_py-0.30.0-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for python-json-logger>=2.0.4 from https://files.pythonhosted.org/packages/51/e5/fecf13f06e5e5f67e8837d777d1bc43fac0ed2b77a676804df5c34744727/python_json_logger-4.0.0-py3-none-any.whl.metadata\n",
      "  Downloading python_json_logger-4.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting pyyaml>=5.3 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for pyyaml>=5.3 from https://files.pythonhosted.org/packages/da/e3/ea007450a105ae919a72393cb06f122f288ef60bba2dc64b26e2646fa315/pyyaml-6.0.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached pyyaml-6.0.3-cp311-cp311-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for rfc3339-validator from https://files.pythonhosted.org/packages/7b/44/4e421b96b67b2daff264473f7465db72fbdf36a07e05494f50300cc7b0c6/rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for rfc3986-validator>=0.1.1 from https://files.pythonhosted.org/packages/9e/51/17023c0f8f1869d8806b979a2bffa3f861f26a3f1a66b094288323fba52f/rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting beautifulsoup4 (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for beautifulsoup4 from https://files.pythonhosted.org/packages/1a/39/47f9197bdd44df24d67ac8893641e16f386c984a0619ef2ee4c51fbbc019/beautifulsoup4-4.14.3-py3-none-any.whl.metadata\n",
      "  Downloading beautifulsoup4-4.14.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bleach[css]!=5.0.0 (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for bleach[css]!=5.0.0 from https://files.pythonhosted.org/packages/cd/3a/577b549de0cc09d95f11087ee63c739bba856cd3952697eec4c4bb91350a/bleach-6.3.0-py3-none-any.whl.metadata\n",
      "  Downloading bleach-6.3.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting defusedxml (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for defusedxml from https://files.pythonhosted.org/packages/07/6c/aa3f2f849e01cb6a001cd8554a88d4c77c5c1a31c95bdf1cf9301e6d9ef4/defusedxml-0.7.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting jupyterlab-pygments (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for jupyterlab-pygments from https://files.pythonhosted.org/packages/b1/dd/ead9d8ea85bf202d90cc513b533f9c363121c7792674f78e0d8a854b63b4/jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata\n",
      "  Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for mistune<4,>=2.0.3 from https://files.pythonhosted.org/packages/9b/f7/4a5e785ec9fbd65146a27b6b70b6cdc161a66f2024e4b04ac06a67f5578b/mistune-3.2.0-py3-none-any.whl.metadata\n",
      "  Downloading mistune-3.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for nbclient>=0.5.0 from https://files.pythonhosted.org/packages/83/a0/5b0c2f11142ed1dddec842457d3f65eaf71a0080894eb6f018755b319c3a/nbclient-0.10.4-py3-none-any.whl.metadata\n",
      "  Downloading nbclient-0.10.4-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for pandocfilters>=1.4.1 from https://files.pythonhosted.org/packages/ef/af/4fbc8cab944db5d21b7e2a5b8e9211a03a79852b1157e2c102fcc61ac440/pandocfilters-1.5.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for fastjsonschema>=2.15 from https://files.pythonhosted.org/packages/cb/a8/20d0723294217e47de6d9e2e40fd4a9d2f7c4b6ef974babd482a59743694/fastjsonschema-2.21.2-py3-none-any.whl.metadata\n",
      "  Downloading fastjsonschema-2.21.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow==2.20.0->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for markdown-it-py>=2.2.0 from https://files.pythonhosted.org/packages/94/54/e7d793b573f298e1c9013b8c4dade17d481164aa517d1d7148619c2cedbf/markdown_it_py-4.0.0-py3-none-any.whl.metadata\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting webencodings (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for webencodings from https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting tinycss2<1.5,>=1.1.0 (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for tinycss2<1.5,>=1.1.0 from https://files.pythonhosted.org/packages/e6/34/ebdc18bae6aa14fbee1a08b63c015c72b64868ff7dae68808ab500c492e2/tinycss2-1.4.0-py3-none-any.whl.metadata\n",
      "  Downloading tinycss2-1.4.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from jedi>=0.18.1->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.8.5)\n",
      "Collecting fqdn (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for fqdn from https://files.pythonhosted.org/packages/cf/58/8acf1b3e91c58313ce5cb67df61001fc9dcd21be4fadb76c1a2d540e09ed/fqdn-1.5.1-py3-none-any.whl.metadata\n",
      "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for isoduration from https://files.pythonhosted.org/packages/7b/55/e5326141505c5d5e34c5e0935d2908a74e4561eca44108fbfb9c13d2911a/isoduration-20.11.0-py3-none-any.whl.metadata\n",
      "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jsonpointer>1.13 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for jsonpointer>1.13 from https://files.pythonhosted.org/packages/71/92/5e77f98553e9e75130c78900d000368476aed74276eb8ae8796f65f00918/jsonpointer-3.0.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rfc3987-syntax>=1.1.0 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for rfc3987-syntax>=1.1.0 from https://files.pythonhosted.org/packages/7e/71/44ce230e1b7fadd372515a97e32a83011f906ddded8d03e3c6aafbdedbb7/rfc3987_syntax-1.1.0-py3-none-any.whl.metadata\n",
      "  Downloading rfc3987_syntax-1.1.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting uri-template (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for uri-template from https://files.pythonhosted.org/packages/e7/00/3fca040d7cf8a32776d3d81a00c8ee7457e00f80c649f1e4a863c8321ae9/uri_template-1.3.0-py3-none-any.whl.metadata\n",
      "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=24.6.0 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for webcolors>=24.6.0 from https://files.pythonhosted.org/packages/e2/cc/e097523dd85c9cf5d354f78310927f1656c422bd7b2613b2db3e3f9a0f2c/webcolors-25.10.0-py3-none-any.whl.metadata\n",
      "  Downloading webcolors-25.10.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow==2.20.0->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for mdurl~=0.1 from https://files.pythonhosted.org/packages/b3/38/89ba8ad64ae25be8de66a6d463314cf1eb366222074cfda9ee839c56a4b4/mdurl-0.1.2-py3-none-any.whl.metadata\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.2.14)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\asus\\desktop\\nlp_tp1\\.venv\\lib\\site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.2.3)\n",
      "Collecting cffi>=1.0.1 (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for cffi>=1.0.1 from https://files.pythonhosted.org/packages/ae/8f/dc5531155e7070361eb1b7e4c1a9d896d0cb21c49f807a6c03fd63fc877e/cffi-2.0.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading cffi-2.0.0-cp311-cp311-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting soupsieve>=1.6.1 (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for soupsieve>=1.6.1 from https://files.pythonhosted.org/packages/48/f3/b67d6ea49ca9154453b6d70b34ea22f3996b9fa55da105a79d8732227adc/soupsieve-2.8.1-py3-none-any.whl.metadata\n",
      "  Downloading soupsieve-2.8.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting pycparser (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for pycparser from https://files.pythonhosted.org/packages/a0/e3/59cd50310fc9b59512193629e1984c1f95e5c8ae6e5d8c69532ccc65a7fe/pycparser-2.23-py3-none-any.whl.metadata\n",
      "  Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "Collecting lark>=1.2.2 (from rfc3987-syntax>=1.1.0->jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for lark>=1.2.2 from https://files.pythonhosted.org/packages/82/3d/14ce75ef66813643812f3093ab17e46d3a206942ce7376d31ec2d36229e7/lark-1.3.1-py3-none-any.whl.metadata\n",
      "  Downloading lark-1.3.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting arrow>=0.15.0 (from isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab==4.5.1->-r requirements.txt (line 7))\n",
      "  Obtaining dependency information for arrow>=0.15.0 from https://files.pythonhosted.org/packages/ed/c9/d7977eaacb9df673210491da99e6a247e93df98c715fc43fd136ce1d3d33/arrow-1.4.0-py3-none-any.whl.metadata\n",
      "  Downloading arrow-1.4.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Using cached torch-2.9.1-cp311-cp311-win_amd64.whl (111.0 MB)\n",
      "Downloading tiktoken-0.12.0-cp311-cp311-win_amd64.whl (879 kB)\n",
      "   ---------------------------------------- 0.0/879.4 kB ? eta -:--:--\n",
      "   ------------------------ -------------- 553.0/879.4 kB 11.8 MB/s eta 0:00:01\n",
      "   --------------------------------------- 879.4/879.4 kB 14.0 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.5/78.5 kB 4.6 MB/s eta 0:00:00\n",
      "Using cached pandas-2.3.3-cp311-cp311-win_amd64.whl (11.3 MB)\n",
      "Using cached matplotlib-3.10.8-cp311-cp311-win_amd64.whl (8.1 MB)\n",
      "Downloading tensorflow-2.20.0-cp311-cp311-win_amd64.whl (331.8 MB)\n",
      "   ---------------------------------------- 0.0/331.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/331.8 MB 39.0 MB/s eta 0:00:09\n",
      "   ---------------------------------------- 2.5/331.8 MB 32.4 MB/s eta 0:00:11\n",
      "   ---------------------------------------- 4.1/331.8 MB 32.9 MB/s eta 0:00:10\n",
      "    --------------------------------------- 5.2/331.8 MB 30.4 MB/s eta 0:00:11\n",
      "    --------------------------------------- 6.8/331.8 MB 30.9 MB/s eta 0:00:11\n",
      "    --------------------------------------- 7.9/331.8 MB 31.5 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 9.4/331.8 MB 30.2 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 10.4/331.8 MB 28.5 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 12.0/331.8 MB 29.7 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 13.6/331.8 MB 28.5 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 14.6/331.8 MB 27.3 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 16.4/331.8 MB 29.7 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 17.8/331.8 MB 28.4 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 19.4/331.8 MB 31.1 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 20.5/331.8 MB 31.2 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 22.3/331.8 MB 31.2 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 23.9/331.8 MB 32.8 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 25.5/331.8 MB 32.8 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 26.6/331.8 MB 32.8 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 27.9/331.8 MB 31.2 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 29.1/331.8 MB 31.2 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 30.4/331.8 MB 29.7 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 31.9/331.8 MB 29.8 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 33.3/331.8 MB 28.5 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 34.8/331.8 MB 28.5 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 36.3/331.8 MB 28.5 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 37.9/331.8 MB 31.2 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 39.4/331.8 MB 29.7 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 40.9/331.8 MB 31.2 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 42.6/331.8 MB 32.7 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 44.4/331.8 MB 34.6 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 45.8/331.8 MB 36.3 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 47.6/331.8 MB 34.4 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 49.0/331.8 MB 34.4 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 50.6/331.8 MB 34.4 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 52.4/331.8 MB 34.4 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 53.9/331.8 MB 34.4 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 55.4/331.8 MB 32.7 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 56.6/331.8 MB 32.8 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 58.3/331.8 MB 32.8 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 59.0/331.8 MB 32.7 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 60.4/331.8 MB 31.2 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 61.8/331.8 MB 29.8 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 63.3/331.8 MB 29.7 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 64.8/331.8 MB 28.4 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 65.6/331.8 MB 27.3 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 67.3/331.8 MB 29.7 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 68.7/331.8 MB 28.4 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 70.3/331.8 MB 29.7 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 71.3/331.8 MB 28.5 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 72.9/331.8 MB 28.5 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 73.9/331.8 MB 27.3 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 75.4/331.8 MB 29.7 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 76.5/331.8 MB 28.4 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 78.3/331.8 MB 29.8 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 79.9/331.8 MB 29.7 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 81.6/331.8 MB 31.2 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 83.1/331.8 MB 32.8 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 84.5/331.8 MB 31.2 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 86.3/331.8 MB 34.4 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 88.0/331.8 MB 34.4 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 89.7/331.8 MB 34.4 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 91.2/331.8 MB 32.8 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 93.0/331.8 MB 34.4 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 94.2/331.8 MB 34.4 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 95.7/331.8 MB 32.8 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 96.9/331.8 MB 32.8 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 98.5/331.8 MB 31.2 MB/s eta 0:00:08\n",
      "   ----------- --------------------------- 100.1/331.8 MB 32.8 MB/s eta 0:00:08\n",
      "   ----------- --------------------------- 101.0/331.8 MB 29.7 MB/s eta 0:00:08\n",
      "   ------------ -------------------------- 102.6/331.8 MB 29.8 MB/s eta 0:00:08\n",
      "   ------------ -------------------------- 103.8/331.8 MB 28.5 MB/s eta 0:00:09\n",
      "   ------------ -------------------------- 105.4/331.8 MB 28.5 MB/s eta 0:00:08\n",
      "   ------------ -------------------------- 106.4/331.8 MB 28.5 MB/s eta 0:00:08\n",
      "   ------------ -------------------------- 108.0/331.8 MB 29.7 MB/s eta 0:00:08\n",
      "   ------------ -------------------------- 109.1/331.8 MB 27.3 MB/s eta 0:00:09\n",
      "   ------------- ------------------------- 110.9/331.8 MB 29.7 MB/s eta 0:00:08\n",
      "   ------------- ------------------------- 112.2/331.8 MB 31.2 MB/s eta 0:00:08\n",
      "   ------------- ------------------------- 113.8/331.8 MB 31.2 MB/s eta 0:00:07\n",
      "   ------------- ------------------------- 115.4/331.8 MB 31.2 MB/s eta 0:00:07\n",
      "   ------------- ------------------------- 117.0/331.8 MB 31.2 MB/s eta 0:00:07\n",
      "   ------------- ------------------------- 118.6/331.8 MB 31.2 MB/s eta 0:00:07\n",
      "   -------------- ------------------------ 119.7/331.8 MB 31.2 MB/s eta 0:00:07\n",
      "   -------------- ------------------------ 121.2/331.8 MB 32.8 MB/s eta 0:00:07\n",
      "   -------------- ------------------------ 122.3/331.8 MB 31.2 MB/s eta 0:00:07\n",
      "   -------------- ------------------------ 123.9/331.8 MB 31.2 MB/s eta 0:00:07\n",
      "   -------------- ------------------------ 125.0/331.8 MB 29.7 MB/s eta 0:00:07\n",
      "   -------------- ------------------------ 126.7/331.8 MB 29.8 MB/s eta 0:00:07\n",
      "   --------------- ----------------------- 128.2/331.8 MB 29.7 MB/s eta 0:00:07\n",
      "   --------------- ----------------------- 129.6/331.8 MB 31.2 MB/s eta 0:00:07\n",
      "   --------------- ----------------------- 131.2/331.8 MB 31.2 MB/s eta 0:00:07\n",
      "   --------------- ----------------------- 132.7/331.8 MB 31.2 MB/s eta 0:00:07\n",
      "   --------------- ----------------------- 134.2/331.8 MB 31.2 MB/s eta 0:00:07\n",
      "   --------------- ----------------------- 135.6/331.8 MB 31.1 MB/s eta 0:00:07\n",
      "   ---------------- ---------------------- 137.7/331.8 MB 32.8 MB/s eta 0:00:06\n",
      "   ---------------- ---------------------- 138.6/331.8 MB 31.2 MB/s eta 0:00:07\n",
      "   ---------------- ---------------------- 139.8/331.8 MB 31.1 MB/s eta 0:00:07\n",
      "   ---------------- ---------------------- 140.8/331.8 MB 28.5 MB/s eta 0:00:07\n",
      "   ---------------- ---------------------- 142.2/331.8 MB 29.8 MB/s eta 0:00:07\n",
      "   ---------------- ---------------------- 142.7/331.8 MB 28.4 MB/s eta 0:00:07\n",
      "   ---------------- ---------------------- 143.9/331.8 MB 26.2 MB/s eta 0:00:08\n",
      "   ----------------- --------------------- 145.0/331.8 MB 26.2 MB/s eta 0:00:08\n",
      "   ----------------- --------------------- 146.0/331.8 MB 25.2 MB/s eta 0:00:08\n",
      "   ----------------- --------------------- 147.5/331.8 MB 24.2 MB/s eta 0:00:08\n",
      "   ----------------- --------------------- 148.7/331.8 MB 24.2 MB/s eta 0:00:08\n",
      "   ----------------- --------------------- 150.4/331.8 MB 25.2 MB/s eta 0:00:08\n",
      "   ----------------- --------------------- 151.7/331.8 MB 26.2 MB/s eta 0:00:07\n",
      "   ----------------- --------------------- 153.1/331.8 MB 28.5 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 153.6/331.8 MB 27.3 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 155.4/331.8 MB 27.3 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 156.4/331.8 MB 28.4 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 158.1/331.8 MB 29.7 MB/s eta 0:00:06\n",
      "   ------------------ -------------------- 159.4/331.8 MB 27.3 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 160.6/331.8 MB 27.3 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 162.1/331.8 MB 28.5 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 163.3/331.8 MB 27.3 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 165.0/331.8 MB 31.2 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 165.9/331.8 MB 28.5 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 167.6/331.8 MB 29.7 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 169.0/331.8 MB 29.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 170.7/331.8 MB 31.1 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 172.0/331.8 MB 31.2 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 173.4/331.8 MB 31.2 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 174.2/331.8 MB 31.1 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 175.5/331.8 MB 29.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 176.5/331.8 MB 28.5 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 177.5/331.8 MB 27.3 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 178.6/331.8 MB 26.2 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 179.6/331.8 MB 25.1 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 180.9/331.8 MB 24.3 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 181.6/331.8 MB 22.6 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 183.1/331.8 MB 24.2 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 184.3/331.8 MB 23.4 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 185.9/331.8 MB 25.2 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 186.8/331.8 MB 25.2 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 188.0/331.8 MB 25.1 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 189.4/331.8 MB 26.2 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 190.3/331.8 MB 25.2 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 191.7/331.8 MB 26.2 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 192.9/331.8 MB 26.2 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 194.4/331.8 MB 27.3 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 195.6/331.8 MB 26.2 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 197.0/331.8 MB 27.3 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 198.5/331.8 MB 27.3 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 200.2/331.8 MB 28.5 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 201.2/331.8 MB 29.8 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 202.3/331.8 MB 29.8 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 203.5/331.8 MB 28.5 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 205.1/331.8 MB 29.7 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 206.5/331.8 MB 29.7 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 208.1/331.8 MB 29.8 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 210.1/331.8 MB 31.2 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 210.9/331.8 MB 29.7 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 212.2/331.8 MB 28.5 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 213.6/331.8 MB 29.7 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 215.3/331.8 MB 31.2 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 216.5/331.8 MB 29.7 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 218.1/331.8 MB 29.7 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 219.0/331.8 MB 27.3 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 220.9/331.8 MB 29.8 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 222.0/331.8 MB 31.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 223.3/331.8 MB 29.7 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 224.7/331.8 MB 29.8 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 226.0/331.8 MB 27.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 227.8/331.8 MB 29.7 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 229.2/331.8 MB 29.7 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 230.9/331.8 MB 31.2 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 232.1/331.8 MB 29.8 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 234.0/331.8 MB 32.7 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 234.7/331.8 MB 29.7 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 236.2/331.8 MB 31.2 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 237.2/331.8 MB 29.7 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 238.9/331.8 MB 29.7 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 240.4/331.8 MB 28.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 242.0/331.8 MB 29.8 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 243.7/331.8 MB 29.8 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 245.4/331.8 MB 32.8 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 246.8/331.8 MB 32.8 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 248.1/331.8 MB 32.7 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 249.7/331.8 MB 32.7 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 251.0/331.8 MB 32.7 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 252.6/331.8 MB 31.1 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 253.8/331.8 MB 29.8 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 255.4/331.8 MB 31.2 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 256.9/331.8 MB 29.7 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 258.3/331.8 MB 31.2 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 259.6/331.8 MB 31.2 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 260.8/331.8 MB 29.7 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 262.2/331.8 MB 28.4 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 263.2/331.8 MB 28.4 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 264.7/331.8 MB 28.5 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 265.7/331.8 MB 27.3 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 267.2/331.8 MB 27.3 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 268.5/331.8 MB 27.3 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 269.8/331.8 MB 27.3 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 271.0/331.8 MB 27.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 272.5/331.8 MB 28.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 273.8/331.8 MB 28.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 274.9/331.8 MB 27.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 276.5/331.8 MB 28.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 277.9/331.8 MB 28.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 279.5/331.8 MB 28.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 280.8/331.8 MB 29.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 282.5/331.8 MB 29.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 283.6/331.8 MB 31.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 285.3/331.8 MB 31.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 286.7/331.8 MB 32.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 288.7/331.8 MB 32.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 290.2/331.8 MB 34.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 291.9/331.8 MB 32.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 293.6/331.8 MB 36.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 295.0/331.8 MB 34.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 296.8/331.8 MB 32.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 296.9/331.8 MB 34.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 298.7/331.8 MB 29.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 300.2/331.8 MB 29.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 302.1/331.8 MB 29.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 303.6/331.8 MB 29.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 305.5/331.8 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 306.7/331.8 MB 29.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 308.4/331.8 MB 34.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 309.7/331.8 MB 36.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 311.3/331.8 MB 32.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 313.0/331.8 MB 32.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 314.3/331.8 MB 32.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 316.3/331.8 MB 32.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 317.5/331.8 MB 32.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 319.2/331.8 MB 32.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 320.4/331.8 MB 32.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 321.9/331.8 MB 32.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 322.9/331.8 MB 29.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  324.4/331.8 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  325.4/331.8 MB 29.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  326.5/331.8 MB 27.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  328.2/331.8 MB 28.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  329.2/331.8 MB 27.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  330.6/331.8 MB 27.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.6/331.8 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.8/331.8 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.8/331.8 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.8/331.8 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.8/331.8 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.8/331.8 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.8/331.8 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.8/331.8 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.8/331.8 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.8/331.8 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.8/331.8 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.8/331.8 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.8/331.8 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.8/331.8 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.8/331.8 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.8/331.8 MB 26.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 331.8/331.8 MB 8.0 MB/s eta 0:00:00\n",
      "Downloading jupyterlab-4.5.1-py3-none-any.whl (12.4 MB)\n",
      "   ---------------------------------------- 0.0/12.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.9/12.4 MB 55.0 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.9/12.4 MB 55.0 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.4/12.4 MB 24.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.5/12.4 MB 24.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 6.1/12.4 MB 25.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.1/12.4 MB 26.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.1/12.4 MB 24.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.2/12.4 MB 24.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.2/12.4 MB 24.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.3/12.4 MB 28.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.4/12.4 MB 26.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.4/12.4 MB 26.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.4/12.4 MB 21.8 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "   ---------------------------------------- 0.0/135.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 135.8/135.8 kB ? eta 0:00:00\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
      "Using cached contourpy-1.3.3-cp311-cp311-win_amd64.whl (225 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading flatbuffers-25.12.19-py2.py3-none-any.whl (26 kB)\n",
      "Using cached fonttools-4.61.1-cp311-cp311-win_amd64.whl (2.3 MB)\n",
      "Downloading fsspec-2026.1.0-py3-none-any.whl (201 kB)\n",
      "   ---------------------------------------- 0.0/201.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 201.8/201.8 kB ? eta 0:00:00\n",
      "Downloading gast-0.7.0-py3-none-any.whl (22 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "   ---------------------------------------- 0.0/57.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 57.5/57.5 kB ? eta 0:00:00\n",
      "Downloading grpcio-1.76.0-cp311-cp311-win_amd64.whl (4.7 MB)\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 1.8/4.7 MB 38.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 3.0/4.7 MB 31.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.7/4.7 MB 33.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.7/4.7 MB 27.5 MB/s eta 0:00:00\n",
      "Downloading h5py-3.15.1-cp311-cp311-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ---------------------------- ----------- 2.1/2.9 MB 44.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.5/2.9 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 23.0 MB/s eta 0:00:00\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "   ---------------------------------------- 0.0/73.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 73.5/73.5 kB ? eta 0:00:00\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.8/78.8 kB 4.6 MB/s eta 0:00:00\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading jupyter_lsp-2.3.0-py3-none-any.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 76.7/76.7 kB ? eta 0:00:00\n",
      "Downloading jupyter_server-2.17.0-py3-none-any.whl (388 kB)\n",
      "   ---------------------------------------- 0.0/388.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 388.2/388.2 kB ? eta 0:00:00\n",
      "Downloading jupyterlab_server-2.28.0-py3-none-any.whl (59 kB)\n",
      "   ---------------------------------------- 0.0/59.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 59.8/59.8 kB ? eta 0:00:00\n",
      "Downloading keras-3.13.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------  1.5/1.5 MB 48.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 32.0 MB/s eta 0:00:00\n",
      "Using cached kiwisolver-1.4.9-cp311-cp311-win_amd64.whl (73 kB)\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.6/26.4 MB 50.9 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 3.0/26.4 MB 38.6 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 4.8/26.4 MB 37.9 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 6.2/26.4 MB 36.3 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 8.0/26.4 MB 36.5 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 9.1/26.4 MB 36.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 11.0/26.4 MB 34.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 11.9/26.4 MB 32.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 13.3/26.4 MB 31.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 14.9/26.4 MB 31.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 15.8/26.4 MB 29.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 17.2/26.4 MB 28.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 18.5/26.4 MB 27.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 20.0/26.4 MB 28.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 21.0/26.4 MB 27.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 22.2/26.4 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 23.1/26.4 MB 27.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.5/26.4 MB 26.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.8/26.4 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 22.6 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.4-cp311-cp311-win_amd64.whl (210 kB)\n",
      "   ---------------------------------------- 0.0/210.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 210.7/210.7 kB 12.5 MB/s eta 0:00:00\n",
      "Using cached networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
      "Downloading notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "Downloading numpy-2.4.1-cp311-cp311-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.7/12.6 MB 35.3 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.7/12.6 MB 34.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 4.0/12.6 MB 28.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.7/12.6 MB 30.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.7/12.6 MB 28.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.4/12.6 MB 31.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.1/12.6 MB 27.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 27.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.0/12.6 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.6 MB 28.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 24.2 MB/s eta 0:00:00\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "   ---------------------------------------- 0.0/71.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 71.9/71.9 kB 3.9 MB/s eta 0:00:00\n",
      "Using cached pillow-12.1.0-cp311-cp311-win_amd64.whl (7.0 MB)\n",
      "Downloading protobuf-6.33.4-cp310-abi3-win_amd64.whl (436 kB)\n",
      "   ---------------------------------------- 0.0/437.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 437.0/437.0 kB 26.7 MB/s eta 0:00:00\n",
      "Using cached pyparsing-3.3.1-py3-none-any.whl (121 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading regex-2026.1.15-cp311-cp311-win_amd64.whl (277 kB)\n",
      "   ---------------------------------------- 0.0/277.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 277.8/277.8 kB 17.8 MB/s eta 0:00:00\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.7/64.7 kB ? eta 0:00:00\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 1.3/5.5 MB 40.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 3.0/5.5 MB 31.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.1/5.5 MB 32.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.5/5.5 MB 32.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 25.2 MB/s eta 0:00:00\n",
      "Downloading termcolor-3.3.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "   ---------------------------------------- 0.0/348.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 348.5/348.5 kB 21.1 MB/s eta 0:00:00\n",
      "Downloading wrapt-2.0.1-cp311-cp311-win_amd64.whl (60 kB)\n",
      "   ---------------------------------------- 0.0/60.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 60.4/60.4 kB 3.1 MB/s eta 0:00:00\n",
      "Downloading filelock-3.20.3-py3-none-any.whl (16 kB)\n",
      "Using cached anyio-4.12.1-py3-none-any.whl (113 kB)\n",
      "Downloading argon2_cffi-25.1.0-py3-none-any.whl (14 kB)\n",
      "Downloading babel-2.17.0-py3-none-any.whl (10.2 MB)\n",
      "   ---------------------------------------- 0.0/10.2 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.9/10.2 MB 61.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.2/10.2 MB 41.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 4.9/10.2 MB 39.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.0/10.2 MB 35.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.5/10.2 MB 34.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.1/10.2 MB 34.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.2/10.2 MB 32.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.2/10.2 MB 28.3 MB/s eta 0:00:00\n",
      "Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "   ---------------------------------------- 0.0/152.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 152.9/152.9 kB 9.5 MB/s eta 0:00:00\n",
      "Downloading charset_normalizer-3.4.4-cp311-cp311-win_amd64.whl (106 kB)\n",
      "   ---------------------------------------- 0.0/107.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 107.0/107.0 kB 6.4 MB/s eta 0:00:00\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading json5-0.13.0-py3-none-any.whl (36 kB)\n",
      "Downloading jsonschema-4.26.0-py3-none-any.whl (90 kB)\n",
      "   ---------------------------------------- 0.0/90.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 90.6/90.6 kB ? eta 0:00:00\n",
      "Downloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
      "Downloading jupyter_server_terminals-0.5.4-py3-none-any.whl (13 kB)\n",
      "Downloading markdown-3.10-py3-none-any.whl (107 kB)\n",
      "   ---------------------------------------- 0.0/107.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 107.7/107.7 kB 6.1 MB/s eta 0:00:00\n",
      "Using cached markupsafe-3.0.3-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading nbconvert-7.16.6-py3-none-any.whl (258 kB)\n",
      "   ---------------------------------------- 0.0/258.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 258.5/258.5 kB 15.5 MB/s eta 0:00:00\n",
      "Downloading nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.5/78.5 kB 4.3 MB/s eta 0:00:00\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading prometheus_client-0.24.1-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.1/64.1 kB 3.4 MB/s eta 0:00:00\n",
      "Downloading pywinpty-3.0.2-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 1.0/2.1 MB 29.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.0/2.1 MB 21.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 18.5 MB/s eta 0:00:00\n",
      "Downloading send2trash-2.1.0-py3-none-any.whl (17 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading terminado-0.18.1-py3-none-any.whl (14 kB)\n",
      "Downloading urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "   ---------------------------------------- 0.0/131.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 131.6/131.6 kB ? eta 0:00:00\n",
      "Downloading websocket_client-1.9.0-py3-none-any.whl (82 kB)\n",
      "   ---------------------------------------- 0.0/82.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 82.6/82.6 kB ? eta 0:00:00\n",
      "Downloading werkzeug-3.1.5-py3-none-any.whl (225 kB)\n",
      "   ---------------------------------------- 0.0/225.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 225.0/225.0 kB ? eta 0:00:00\n",
      "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.18.0-cp311-cp311-win_amd64.whl (312 kB)\n",
      "   ---------------------------------------- 0.0/312.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 312.2/312.2 kB ? eta 0:00:00\n",
      "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "   ---------------------------------------- 0.0/243.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 243.4/243.4 kB 15.5 MB/s eta 0:00:00\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "   ---------------------------------------- 0.0/67.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 67.6/67.6 kB ? eta 0:00:00\n",
      "Downloading fastjsonschema-2.21.2-py3-none-any.whl (24 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "   ---------------------------------------- 0.0/87.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 87.3/87.3 kB ? eta 0:00:00\n",
      "Downloading mistune-3.2.0-py3-none-any.whl (53 kB)\n",
      "   ---------------------------------------- 0.0/53.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 53.6/53.6 kB ? eta 0:00:00\n",
      "Downloading nbclient-0.10.4-py3-none-any.whl (25 kB)\n",
      "Downloading pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading python_json_logger-4.0.0-py3-none-any.whl (15 kB)\n",
      "Using cached pyyaml-6.0.3-cp311-cp311-win_amd64.whl (158 kB)\n",
      "Downloading referencing-0.37.0-py3-none-any.whl (26 kB)\n",
      "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Downloading rpds_py-0.30.0-cp311-cp311-win_amd64.whl (236 kB)\n",
      "   ---------------------------------------- 0.0/236.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 236.0/236.0 kB ? eta 0:00:00\n",
      "Downloading argon2_cffi_bindings-25.1.0-cp39-abi3-win_amd64.whl (31 kB)\n",
      "Downloading beautifulsoup4-4.14.3-py3-none-any.whl (107 kB)\n",
      "   ---------------------------------------- 0.0/107.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 107.7/107.7 kB ? eta 0:00:00\n",
      "Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Downloading cffi-2.0.0-cp311-cp311-win_amd64.whl (182 kB)\n",
      "   ---------------------------------------- 0.0/182.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 182.8/182.8 kB 10.8 MB/s eta 0:00:00\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading rfc3987_syntax-1.1.0-py3-none-any.whl (8.0 kB)\n",
      "Downloading soupsieve-2.8.1-py3-none-any.whl (36 kB)\n",
      "Downloading tinycss2-1.4.0-py3-none-any.whl (26 kB)\n",
      "Downloading webcolors-25.10.0-py3-none-any.whl (14 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading bleach-6.3.0-py3-none-any.whl (164 kB)\n",
      "   ---------------------------------------- 0.0/164.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 164.4/164.4 kB 9.6 MB/s eta 0:00:00\n",
      "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Downloading arrow-1.4.0-py3-none-any.whl (68 kB)\n",
      "   ---------------------------------------- 0.0/68.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 68.8/68.8 kB 3.7 MB/s eta 0:00:00\n",
      "Downloading lark-1.3.1-py3-none-any.whl (113 kB)\n",
      "   ---------------------------------------- 0.0/113.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 113.2/113.2 kB ? eta 0:00:00\n",
      "Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "   ---------------------------------------- 0.0/118.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 118.1/118.1 kB ? eta 0:00:00\n",
      "Installing collected packages: webencodings, pytz, namex, mpmath, libclang, flatbuffers, fastjsonschema, wrapt, wheel, websocket-client, webcolors, urllib3, uri-template, tzdata, tqdm, tinycss2, termcolor, tensorboard-data-server, sympy, soupsieve, send2trash, rpds-py, rfc3986-validator, rfc3339-validator, regex, pyyaml, pywinpty, python-json-logger, pyparsing, pycparser, protobuf, prometheus-client, pillow, pandocfilters, overrides, optree, opt_einsum, numpy, networkx, mistune, mdurl, MarkupSafe, markdown, lark, kiwisolver, jupyterlab-pygments, jsonpointer, json5, idna, h11, grpcio, google_pasta, gast, fsspec, fqdn, fonttools, filelock, defusedxml, cycler, charset_normalizer, certifi, bleach, babel, attrs, async-lru, absl-py, werkzeug, terminado, rfc3987-syntax, requests, referencing, pandas, ml_dtypes, markdown-it-py, jinja2, httpcore, h5py, contourpy, cffi, beautifulsoup4, astunparse, arrow, anyio, torch, tiktoken, tensorboard, rich, matplotlib, jupyter-server-terminals, jsonschema-specifications, isoduration, httpx, argon2-cffi-bindings, keras, jsonschema, argon2-cffi, tensorflow, nbformat, nbclient, jupyter-events, nbconvert, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab\n",
      "Successfully installed MarkupSafe-3.0.3 absl-py-2.3.1 anyio-4.12.1 argon2-cffi-25.1.0 argon2-cffi-bindings-25.1.0 arrow-1.4.0 astunparse-1.6.3 async-lru-2.0.5 attrs-25.4.0 babel-2.17.0 beautifulsoup4-4.14.3 bleach-6.3.0 certifi-2026.1.4 cffi-2.0.0 charset_normalizer-3.4.4 contourpy-1.3.3 cycler-0.12.1 defusedxml-0.7.1 fastjsonschema-2.21.2 filelock-3.20.3 flatbuffers-25.12.19 fonttools-4.61.1 fqdn-1.5.1 fsspec-2026.1.0 gast-0.7.0 google_pasta-0.2.0 grpcio-1.76.0 h11-0.16.0 h5py-3.15.1 httpcore-1.0.9 httpx-0.28.1 idna-3.11 isoduration-20.11.0 jinja2-3.1.6 json5-0.13.0 jsonpointer-3.0.0 jsonschema-4.26.0 jsonschema-specifications-2025.9.1 jupyter-events-0.12.0 jupyter-lsp-2.3.0 jupyter-server-2.17.0 jupyter-server-terminals-0.5.4 jupyterlab-4.5.1 jupyterlab-pygments-0.3.0 jupyterlab-server-2.28.0 keras-3.13.1 kiwisolver-1.4.9 lark-1.3.1 libclang-18.1.1 markdown-3.10 markdown-it-py-4.0.0 matplotlib-3.10.8 mdurl-0.1.2 mistune-3.2.0 ml_dtypes-0.5.4 mpmath-1.3.0 namex-0.1.0 nbclient-0.10.4 nbconvert-7.16.6 nbformat-5.10.4 networkx-3.6.1 notebook-shim-0.2.4 numpy-2.4.1 opt_einsum-3.4.0 optree-0.18.0 overrides-7.7.0 pandas-2.3.3 pandocfilters-1.5.1 pillow-12.1.0 prometheus-client-0.24.1 protobuf-6.33.4 pycparser-2.23 pyparsing-3.3.1 python-json-logger-4.0.0 pytz-2025.2 pywinpty-3.0.2 pyyaml-6.0.3 referencing-0.37.0 regex-2026.1.15 requests-2.32.5 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rfc3987-syntax-1.1.0 rich-14.2.0 rpds-py-0.30.0 send2trash-2.1.0 soupsieve-2.8.1 sympy-1.14.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.3.0 terminado-0.18.1 tiktoken-0.12.0 tinycss2-1.4.0 torch-2.9.1 tqdm-4.67.1 tzdata-2025.3 uri-template-1.3.0 urllib3-2.6.3 webcolors-25.10.0 webencodings-0.5.1 websocket-client-1.9.0 werkzeug-3.1.5 wheel-0.45.1 wrapt-2.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "# --- INSTRUCTOR CODE ---\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed979fc7",
   "metadata": {},
   "source": [
    "## Background & Mathematical Formulation\n",
    "\n",
    "Fine-tuning Large Language Models (LLMs) updates all model parameters, which is computationally expensive. LoRA freezes the pre-trained weights and injects trainable rank decomposition matrices.\n",
    "\n",
    "Given a pre-trained weight matrix $W_0 \\in \\mathbb{R}^{d_{out} \\times d_{in}}$, LoRA constrains the update $\\Delta W$ by representing it with a low-rank decomposition:\n",
    "\n",
    "$$W_0 + \\Delta W = W_0 + B A$$\n",
    "\n",
    "Where:\n",
    "- $B \\in \\mathbb{R}^{d_{out} \\times r}$\n",
    "- $A \\in \\mathbb{R}^{r \\times d_{in}}$\n",
    "- $r \\ll \\min(d_{in}, d_{out})$ is the rank.\n",
    "\n",
    "The Forward Pass:\n",
    "\n",
    "$$h = W_0 x + \\frac{\\alpha}{r} (B A x)$$\n",
    "\n",
    "- $\\alpha$ is a scaling constant.\n",
    "- $A$ is initialized with random Gaussian values.\n",
    "- $B$ is initialized with zeros (so training starts with no changes to the model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbec02b",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and our provided GPT utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b15a71ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- INSTRUCTOR CODE ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "from gpt_utils import GPTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "685e3ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x27d7fd3d330>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_STATE = 123 \n",
    "torch.manual_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2a222d",
   "metadata": {},
   "source": [
    "## Implementing the LoRA Layer\n",
    "\n",
    "In this exercise, you will create the LoRALayer module. This module computes the $\\Delta Wx$ term (the branch on the right side of the diagram seen during the lecture).\n",
    "\n",
    "### **Exercise 1**: Define the LoRA Module\n",
    "\n",
    "Requirements:\n",
    "1. Define dimensions for parameters A and B based on in_dim, out_dim, and rank.\n",
    "2. Initialize A with kaiming_uniform_ (or small random normal).\n",
    "3. Initialize B with zeros.\n",
    "4. Implement the forward pass including the scaling factor $\\frac{\\alpha}{r}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be539ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoRALayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.rank = rank\n",
    "        self.alpha = alpha\n",
    "        self.scaling = alpha / rank  # alpha/r\n",
    "\n",
    "        # A: rank x in_dim, B: out_dim x rank\n",
    "        self.A = nn.Parameter(torch.empty(rank, in_dim))\n",
    "        self.B = nn.Parameter(torch.empty(out_dim, rank))\n",
    "\n",
    "        # Init\n",
    "        nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))\n",
    "        nn.init.zeros_(self.B)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (..., in_dim)\n",
    "        # (..., rank)\n",
    "        x_a = torch.matmul(x, self.A.t())\n",
    "        # (..., out_dim)\n",
    "        x_ab = torch.matmul(x_a, self.B.t())\n",
    "        return self.scaling * x_ab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0767c887",
   "metadata": {},
   "source": [
    "## Wrapping Linear Layers\n",
    "\n",
    "We rarely replace the layer entirely; instead, we want a layer that holds both the frozen original weights and the new LoRA weights.\n",
    "\n",
    "### **Exercise 2**: The LinearWithLoRA Wrapper\n",
    "\n",
    "Requirements:\n",
    "1. Store the original linear layer.\n",
    "2. Create a self.lora instance using the dimensions of the original linear layer.\n",
    "3. In forward, add the output of the original layer to the output of the LoRA layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3d268ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Passed: Wrapper acts identically to original layer at initialization.\n"
     ]
    }
   ],
   "source": [
    "class LinearWithLoRA(nn.Module):\n",
    "    def __init__(self, linear_layer, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.linear = linear_layer\n",
    "\n",
    "        self.lora = LoRALayer(\n",
    "            in_dim=linear_layer.in_features,\n",
    "            out_dim=linear_layer.out_features,\n",
    "            rank=rank,\n",
    "            alpha=alpha\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x) + self.lora(x)\n",
    "\n",
    "# --- Sanity Check ---\n",
    "input_x = torch.randn(1, 128)\n",
    "original_layer = nn.Linear(128, 64)\n",
    "lora_wrapped = LinearWithLoRA(original_layer, rank=4, alpha=8)\n",
    "\n",
    "assert torch.allclose(original_layer(input_x), lora_wrapped(input_x))\n",
    "print(\"Test Passed: Wrapper acts identically to original layer at initialization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201146a1",
   "metadata": {},
   "source": [
    "## Injecting LoRA into GPTModel\n",
    "\n",
    "Now we need to modify our existing GPTModel. We cannot manually rewrite the class. Instead, we will iterate through the model's modules and replace specific layers dynamically.\n",
    "\n",
    "In GPTModel, the transformer blocks are stored in *self.trf_blocks*. Inside those, we have attention mechanisms (att) containing W_query, W_key, W_value, or a combined c_attn.\n",
    "\n",
    "Note: For this lab, to keep it simple, we will replace all nn.Linear layers except the final output head.\n",
    "\n",
    "### **Exercise 3**: Recursive Model Modification\n",
    "\n",
    "Requirements:\n",
    "1. Iterate through named children of the model.\n",
    "2. If a module is nn.Linear, wrap it in LinearWithLoRA.\n",
    "3. Important: Skip the final output layer (often named out_head or similar in gpt_utils), as we usually don't want to reduce the rank of the vocabulary projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "116d7337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_linear_with_lora(model, rank, alpha):\n",
    "    \"\"\"\n",
    "    Recursively replaces nn.Linear with LinearWithLoRA, skipping out_head.\n",
    "    \"\"\"\n",
    "    for name, module in model.named_children():\n",
    "\n",
    "        if isinstance(module, nn.Linear):\n",
    "            if name == \"out_head\":\n",
    "                continue\n",
    "\n",
    "            new_layer = LinearWithLoRA(module, rank=rank, alpha=alpha)\n",
    "            setattr(model, name, new_layer)\n",
    "\n",
    "        else:\n",
    "            replace_linear_with_lora(module, rank, alpha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d5f1d3",
   "metadata": {},
   "source": [
    "## Freeze & Verify\n",
    "\n",
    "We have injected the layers, but currently, everything is still trainable. We must freeze the original weights.\n",
    "\n",
    "### **Exercise 4**: Freezing and Counting Parameters\n",
    "Requirements:\n",
    "1. Set requires_grad = False for all parameters.\n",
    "2. Iterate through the model; if a layer is LinearWithLoRA, unfreeze self.lora.A and self.lora.B.\n",
    "3. Calculate the ratio of trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5764f658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_and_activate_lora(model):\n",
    "    # 1) Freeze everything\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # 2) Unfreeze only LoRA A and B\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, LinearWithLoRA):\n",
    "            module.lora.A.requires_grad = True\n",
    "            module.lora.B.requires_grad = True\n",
    "\n",
    "\n",
    "def print_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params:,} || all params: {all_param:,} || \"\n",
    "        f\"trainable%: {100 * trainable_params / all_param:.2f}%\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ab6916",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "Let's download and initialize the model from gpt_utils, then apply our LoRA transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73aae7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2_weights\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2_weights\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2_weights\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2_weights\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2_weights\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2_weights\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2_weights\\124M\\vocab.bpe\n",
      "Weights downloaded and loaded into memory.\n",
      "Original Model Structure (Truncated):\n",
      "TransformerBlock(\n",
      "  (att): MultiHeadAttention(\n",
      "    (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ff): FeedForward(\n",
      "    (layers): Sequential(\n",
      "      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (1): GELU()\n",
      "      (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (norm1): LayerNorm()\n",
      "  (norm2): LayerNorm()\n",
      "  (drop_resid): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "\n",
      "Model Structure After LoRA (Truncated):\n",
      "TransformerBlock(\n",
      "  (att): MultiHeadAttention(\n",
      "    (W_query): LinearWithLoRA(\n",
      "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (lora): LoRALayer()\n",
      "    )\n",
      "    (W_key): LinearWithLoRA(\n",
      "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (lora): LoRALayer()\n",
      "    )\n",
      "    (W_value): LinearWithLoRA(\n",
      "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (lora): LoRALayer()\n",
      "    )\n",
      "    (out_proj): LinearWithLoRA(\n",
      "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (lora): LoRALayer()\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ff): FeedForward(\n",
      "    (layers): Sequential(\n",
      "      (0): LinearWithLoRA(\n",
      "        (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (lora): LoRALayer()\n",
      "      )\n",
      "      (1): GELU()\n",
      "      (2): LinearWithLoRA(\n",
      "        (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (lora): LoRALayer()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm1): LayerNorm()\n",
      "  (norm2): LayerNorm()\n",
      "  (drop_resid): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "\n",
      "Parameter Count:\n",
      "trainable params: 1,327,104 || all params: 164,364,288 || trainable%: 0.81%\n"
     ]
    }
   ],
   "source": [
    "from gpt_utils import GPTModel, download_and_load_gpt2, load_weights_into_gpt\n",
    "\n",
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2_weights\")\n",
    "print(\"Weights downloaded and loaded into memory.\")\n",
    "\n",
    "model_config = {\n",
    "    \"vocab_size\": settings[\"n_vocab\"],\n",
    "    \"context_length\": settings[\"n_ctx\"],\n",
    "    \"emb_dim\": settings[\"n_embd\"],\n",
    "    \"n_heads\": settings[\"n_head\"],\n",
    "    \"n_layers\": settings[\"n_layer\"],\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": True,\n",
    "}\n",
    "\n",
    "model = GPTModel(model_config)\n",
    "load_weights_into_gpt(model, params)\n",
    "\n",
    "print(\"Original Model Structure (Truncated):\")\n",
    "print(model.trf_blocks[0])\n",
    "\n",
    "replace_linear_with_lora(model, rank=8, alpha=16)\n",
    "freeze_and_activate_lora(model)\n",
    "\n",
    "print(\"\\nModel Structure After LoRA (Truncated):\")\n",
    "print(model.trf_blocks[0])\n",
    "\n",
    "print(\"\\nParameter Count:\")\n",
    "print_trainable_parameters(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c26ffba",
   "metadata": {},
   "source": [
    "Now, we call all the methods we have defined above, and put everything together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4001e300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Structure (Truncated):\n",
      "TransformerBlock(\n",
      "  (att): MultiHeadAttention(\n",
      "    (W_query): LinearWithLoRA(\n",
      "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (lora): LoRALayer()\n",
      "    )\n",
      "    (W_key): LinearWithLoRA(\n",
      "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (lora): LoRALayer()\n",
      "    )\n",
      "    (W_value): LinearWithLoRA(\n",
      "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (lora): LoRALayer()\n",
      "    )\n",
      "    (out_proj): LinearWithLoRA(\n",
      "      (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (lora): LoRALayer()\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ff): FeedForward(\n",
      "    (layers): Sequential(\n",
      "      (0): LinearWithLoRA(\n",
      "        (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (lora): LoRALayer()\n",
      "      )\n",
      "      (1): GELU()\n",
      "      (2): LinearWithLoRA(\n",
      "        (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (lora): LoRALayer()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm1): LayerNorm()\n",
      "  (norm2): LayerNorm()\n",
      "  (drop_resid): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "\n",
      "Model Structure After LoRA (Truncated):\n",
      "TransformerBlock(\n",
      "  (att): MultiHeadAttention(\n",
      "    (W_query): LinearWithLoRA(\n",
      "      (linear): LinearWithLoRA(\n",
      "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (lora): LoRALayer()\n",
      "      )\n",
      "      (lora): LoRALayer()\n",
      "    )\n",
      "    (W_key): LinearWithLoRA(\n",
      "      (linear): LinearWithLoRA(\n",
      "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (lora): LoRALayer()\n",
      "      )\n",
      "      (lora): LoRALayer()\n",
      "    )\n",
      "    (W_value): LinearWithLoRA(\n",
      "      (linear): LinearWithLoRA(\n",
      "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (lora): LoRALayer()\n",
      "      )\n",
      "      (lora): LoRALayer()\n",
      "    )\n",
      "    (out_proj): LinearWithLoRA(\n",
      "      (linear): LinearWithLoRA(\n",
      "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (lora): LoRALayer()\n",
      "      )\n",
      "      (lora): LoRALayer()\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ff): FeedForward(\n",
      "    (layers): Sequential(\n",
      "      (0): LinearWithLoRA(\n",
      "        (linear): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (lora): LoRALayer()\n",
      "      )\n",
      "      (1): GELU()\n",
      "      (2): LinearWithLoRA(\n",
      "        (linear): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (lora): LoRALayer()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm1): LayerNorm()\n",
      "  (norm2): LayerNorm()\n",
      "  (drop_resid): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "\n",
      "Parameter Count:\n",
      "trainable params: 2,654,208 || all params: 165,691,392 || trainable%: 1.60%\n"
     ]
    }
   ],
   "source": [
    "# --- INSTRUCTOR CODE ---\n",
    "\n",
    "print(\"Original Model Structure (Truncated):\")\n",
    "print(model.trf_blocks[0]) # Print first block to see standard Linear layers\n",
    "\n",
    "# Apply LoRA Replacement\n",
    "# Rank 8, Alpha 16 (Alpha is usually set to 2x Rank as a rule of thumb)\n",
    "replace_linear_with_lora(model, rank=8, alpha=16)\n",
    "\n",
    "# 3. Freeze Weights\n",
    "freeze_and_activate_lora(model)\n",
    "\n",
    "# 4. Check Results\n",
    "print(\"\\nModel Structure After LoRA (Truncated):\")\n",
    "print(model.trf_blocks[0])\n",
    "\n",
    "print(\"\\nParameter Count:\")\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a264553",
   "metadata": {},
   "source": [
    "**Question 1:** Do you see any difference between \"Original Model Structure (Truncated)\" and \"Model Structure After LoRA (Truncated)\"? Do you see the LinearWithLoRA you have defined above?\n",
    "\n",
    "**Question 2:** What is the number of trainable parameters, all parameters, and the fraction of trainable parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2e97c6",
   "metadata": {},
   "source": [
    "## Training Loop Verification\n",
    "\n",
    "Finally, let's prove that gradients are only generated for the specific LoRA parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8076639f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Verification:\n",
      "Parameters with gradients: 288\n",
      "Frozen parameters correctly without gradients: 197\n",
      "SUCCESS: Gradients are flowing correctly only into LoRA parameters.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "dummy_input = torch.randint(0, 1000, (batch_size, 256))\n",
    "dummy_target = torch.randint(0, 1000, (batch_size, 256))\n",
    "\n",
    "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.AdamW(trainable_params, lr=1e-3)\n",
    "\n",
    "logits = model(dummy_input)\n",
    "loss = torch.nn.functional.cross_entropy(\n",
    "    logits.view(-1, model_config[\"vocab_size\"]),\n",
    "    dummy_target.view(-1)\n",
    ")\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "\n",
    "print(\"\\nGradient Verification:\")\n",
    "grads_found = 0\n",
    "grads_missing = 0\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        if param.grad is not None:\n",
    "            grads_found += 1\n",
    "        else:\n",
    "            print(f\"WARNING: Trainable parameter {name} has no gradient.\")\n",
    "    else:\n",
    "        if param.grad is not None:\n",
    "            print(f\"ERROR: Frozen parameter {name} has a gradient!\")\n",
    "        else:\n",
    "            grads_missing += 1\n",
    "\n",
    "print(f\"Parameters with gradients: {grads_found}\")\n",
    "print(f\"Frozen parameters correctly without gradients: {grads_missing}\")\n",
    "\n",
    "if grads_found > 0 and grads_missing > 0:\n",
    "    print(\"SUCCESS: Gradients are flowing correctly only into LoRA parameters.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff671a8",
   "metadata": {},
   "source": [
    "## SPAM Classification\n",
    "\n",
    "Let's now work the Spam Classification task again, but this time using the LoRA-adapted model. \n",
    "This follows the example from the previous session."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2933e138",
   "metadata": {},
   "source": [
    "### Download and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8beff640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5572 examples.\n",
      "  label                                               text\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
      "Balanced Dataset size: 1494\n",
      "Size of train_df: 1195\n",
      "Size of test_df: 299\n",
      "Distribution of labels in the dataset:\n",
      "train:\n",
      "label\n",
      "1    598\n",
      "0    597\n",
      "Name: count, dtype: int64\n",
      "test:\n",
      "label\n",
      "0    150\n",
      "1    149\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- INSTRUCTOR CODE ---\n",
    "\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Download the dataset\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = os.path.join(extracted_path, \"SMSSpamCollection\")\n",
    "\n",
    "if not os.path.exists(zip_path):\n",
    "    print(\"Downloading dataset...\")\n",
    "    urllib.request.urlretrieve(url, zip_path)\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "    print(\"Dataset downloaded and extracted.\")\n",
    "\n",
    "# Load into DataFrame\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"label\", \"text\"])\n",
    "print(f\"Loaded {len(df)} examples.\")\n",
    "print(df.head())\n",
    "\n",
    "# Class Balancing (primarily for speed in the lab)\n",
    "spam_df = df[df[\"label\"] == \"spam\"]\n",
    "ham_df = df[df[\"label\"] == \"ham\"].sample(len(spam_df), random_state=RANDOM_STATE)\n",
    "df = pd.concat([spam_df, ham_df]).reset_index(drop=True)\n",
    "\n",
    "# Map labels to integers\n",
    "df[\"label\"] = df[\"label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "print(f\"Balanced Dataset size: {len(df)}\")\n",
    "\n",
    "df = df.sample(frac=1, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "\n",
    "train_size = int(0.8 * len(df))\n",
    "train_df = df[:train_size]\n",
    "test_df = df[train_size:]\n",
    "\n",
    "print(f\"Size of train_df: {len(train_df)}\")\n",
    "print(f\"Size of test_df: {len(test_df)}\")\n",
    "\n",
    "print(\"Distribution of labels in the dataset:\")\n",
    "print(\"train:\")\n",
    "print(train_df['label'].value_counts())\n",
    "print(\"test:\")\n",
    "print(test_df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb81f48",
   "metadata": {},
   "source": [
    "Define Dataset and DataLoader, similarly to previous session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7b33971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- INSTRUCTOR CODE ---\n",
    "\n",
    "import tiktoken\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=256):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        text = row['text']\n",
    "        label = row['label']\n",
    "        \n",
    "        # Tokenize\n",
    "        encoded = self.tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "        \n",
    "        # Truncate\n",
    "        encoded = encoded[:self.max_length]\n",
    "        \n",
    "        # Pad (GPT-2 usually uses <|endoftext|> as padding)\n",
    "        pad_len = self.max_length - len(encoded)\n",
    "        encoded = encoded + [50256] * pad_len # 50256 is <|endoftext|> in GPT2\n",
    "        \n",
    "        return torch.tensor(encoded, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Initialize Tokenizer\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# Create Loaders\n",
    "train_loader = DataLoader(SpamDataset(train_df, tokenizer), batch_size=8, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(SpamDataset(test_df, tokenizer), batch_size=8, shuffle=False, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9b9dc8",
   "metadata": {},
   "source": [
    "We now modify the Model for Classification, replacing the final layer (out_head)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e686056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Output Head: Linear(in_features=768, out_features=2, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# --- INSTRUCTOR CODE ---\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "# Check input dimension of the current head\n",
    "hidden_dim = model.out_head.in_features\n",
    "\n",
    "# Replace the head\n",
    "model.out_head = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "# Move model to device (if using GPU, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(\"New Output Head:\", model.out_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f4b703",
   "metadata": {},
   "source": [
    "We previously froze everything except LoRA. Now we added a new head, let's make it unfrozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6889edeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,655,746 || all params: 127,095,554 || trainable%: 2.09%\n"
     ]
    }
   ],
   "source": [
    "# --- INSTRUCTOR CODE ---\n",
    "\n",
    "def set_classification_trainable(model):\n",
    "    # Ensure LoRA layers are trainable (A and B)\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, LinearWithLoRA):\n",
    "            module.lora.A.requires_grad = True\n",
    "            module.lora.B.requires_grad = True\n",
    "    \n",
    "    # Ensure the new classification head is trainable\n",
    "    for param in model.out_head.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "set_classification_trainable(model)\n",
    "\n",
    "# Verify count again\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dec47a",
   "metadata": {},
   "source": [
    "**Question 3:** Check the number (and fraction) of trainable parameters, and compare it with the one above. Do you see any differences? Can you describe them?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a5f0ac",
   "metadata": {},
   "source": [
    "The Training Loop\n",
    "Context: Standard PyTorch loop. Note that GPT models output [batch, seq_len, hidden]. For classification, we usually take the hidden state of the last token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c03d3f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- INSTRUCTOR CODE ---\n",
    "\n",
    "import time\n",
    "\n",
    "def train_classifier(model, loader, optimizer, device, epochs=1):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward Pass\n",
    "            # The model outputs (batch, seq_len, num_classes)\n",
    "            logits = model(inputs)\n",
    "            \n",
    "            # Select the last token for classification\n",
    "            # last_token_logits = logits[:, -1, :]  \n",
    "            # NOTE: this (the line above) was an error in the code provided with the previous lab: it was using the last token (which is most often PAD), \n",
    "            #   not the last non padding token. \n",
    "            # Select the last NON-PADDING token\n",
    "            #   Create a mask (1 for real tokens, 0 for PAD); 50256 is the PAD token ID\n",
    "            mask = (inputs != 50256)\n",
    "            \n",
    "            # Find the index of the last real token\n",
    "            #    Summing the mask gives the length. Subtract 1 for 0-based index.\n",
    "            #    .clamp(min=0) prevents errors if a sequence is empty (unlikely)\n",
    "            last_idx = (mask.sum(dim=1) - 1).clamp(min=0)\n",
    "            \n",
    "            # Select the logits at those specific indices\n",
    "            #    We use torch.arange for the batch dimension\n",
    "            batch_indices = torch.arange(inputs.size(0), device=device)\n",
    "            last_token_logits = logits[batch_indices, last_idx, :]\n",
    "            \n",
    "            loss = torch.nn.functional.cross_entropy(last_token_logits, targets)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Calculate accuracy for monitoring\n",
    "            preds = torch.argmax(last_token_logits, dim=-1)\n",
    "            correct += (preds == targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1} | Batch {batch_idx} | Loss: {loss.item():.4f}\")\n",
    "\n",
    "        acc = correct / total * 100\n",
    "        print(f\"Epoch {epoch+1} Finished | Avg Loss: {total_loss/len(loader):.4f} | Acc: {acc:.2f}% | Time: {time.time()-start_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d347648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Batch 0 | Loss: 1.5386\n",
      "Epoch 1 | Batch 10 | Loss: 0.4617\n",
      "Epoch 1 | Batch 20 | Loss: 0.0964\n",
      "Epoch 1 | Batch 30 | Loss: 0.0483\n",
      "Epoch 1 | Batch 40 | Loss: 1.4296\n",
      "Epoch 1 | Batch 50 | Loss: 0.0830\n",
      "Epoch 1 | Batch 60 | Loss: 0.0249\n",
      "Epoch 1 | Batch 70 | Loss: 0.0875\n",
      "Epoch 1 | Batch 80 | Loss: 0.0183\n",
      "Epoch 1 | Batch 90 | Loss: 0.0356\n",
      "Epoch 1 | Batch 100 | Loss: 0.3503\n",
      "Epoch 1 | Batch 110 | Loss: 0.0172\n",
      "Epoch 1 | Batch 120 | Loss: 0.4629\n",
      "Epoch 1 | Batch 130 | Loss: 0.0245\n",
      "Epoch 1 | Batch 140 | Loss: 0.0036\n",
      "Epoch 1 Finished | Avg Loss: 0.1980 | Acc: 92.20% | Time: 1646.37s\n"
     ]
    }
   ],
   "source": [
    "# --- INSTRUCTOR CODE ---\n",
    "\n",
    "# Setup Optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    [p for p in model.parameters() if p.requires_grad], \n",
    "    lr=5e-4    # TODO: Potentially test with different learning rates\n",
    ")\n",
    "\n",
    "# Run Training\n",
    "train_classifier(model, train_loader, optimizer, device, epochs=1)  # TODO: Potentially test with different numbers of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02917255",
   "metadata": {},
   "source": [
    "**Question 4:** Can you describe the trend of the loss, and the final accuracy. Is it reasonable considering the task at hand?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e655eb",
   "metadata": {},
   "source": [
    "We can now test the accuracy on the held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd866e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- INSTRUCTOR CODE ---\n",
    "\n",
    "def evaluate_accuracy(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            logits = model(inputs)\n",
    "            \n",
    "            # Select last \"real\" token logits\n",
    "            mask = (inputs != 50256)\n",
    "            last_idx = (mask.sum(dim=1) - 1).clamp(min=0)\n",
    "            batch_idx = torch.arange(inputs.size(0), device=device)\n",
    "            last_token_logits = logits[batch_idx, last_idx, :]\n",
    "            # Select last token logits (same logic as training)\n",
    "            # last_token_logits = logits[:, -1, :]\n",
    "            \n",
    "            # Get predictions\n",
    "            predictions = torch.argmax(last_token_logits, dim=-1)\n",
    "            \n",
    "            # Compare with targets\n",
    "            correct += (predictions == targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "            \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "553c3a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy: 97.99%\n"
     ]
    }
   ],
   "source": [
    "# --- INSTRUCTOR CODE ---\n",
    "\n",
    "# Run evaluation\n",
    "test_accuracy = evaluate_accuracy(model, test_loader, device)\n",
    "print(f\"Test Set Accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c713ca7",
   "metadata": {},
   "source": [
    "**Question 5:** How is the accuracy, and how does it compare to the Train set accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c1b259",
   "metadata": {},
   "source": [
    "Finally, we can do a quick inference test, to see how the model classifies new texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f06b8950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- INSTRUCTOR CODE ---\n",
    "\n",
    "def classify_text(text, model, tokenizer, device):\n",
    "    model.eval()\n",
    "    \n",
    "    # Preprocess\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded = encoded[:256] # Truncate\n",
    "    tensor_input = torch.tensor([encoded], dtype=torch.long).to(device) # Add batch dim\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(tensor_input)\n",
    "        last_token_logits = logits[:, -1, :]\n",
    "        probs = torch.softmax(last_token_logits, dim=-1)\n",
    "        pred_label = torch.argmax(probs, dim=-1).item()\n",
    "        \n",
    "    label_map = {0: \"HAM (Normal)\", 1: \"SPAM\"}\n",
    "    print(f\"Text: '{text}'\")\n",
    "    print(f\"Prediction: {label_map[pred_label]} (Confidence: {probs[0][pred_label]:.2f})\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d358eedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 'There is a big cash prize for you, call immediately.'\n",
      "Prediction: SPAM (Confidence: 0.60)\n",
      "------------------------------\n",
      "Text: 'Hey, are we still meeting for lunch tomorrow?'\n",
      "Prediction: HAM (Normal) (Confidence: 1.00)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# TODO: add the text you want to test.\n",
    "classify_text(\"There is a big cash prize for you, call immediately.\", model, tokenizer, device)\n",
    "classify_text(\"Hey, are we still meeting for lunch tomorrow?\", model, tokenizer, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b4d416",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
